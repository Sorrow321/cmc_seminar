Задача - построение чат бота для торговых центров. Реализуемая фича - поиск по товарам с помощью запроса, заданного на естественном языке.

**22.10.2020** Примерно получили представление, что нужно для построения нужной нам системы. Пока остановились на том, что нам нужна модель ранжирования. Создали некоторый baseline без использования DL (на основе обычного bag of words и меры Жаккара). Соответственно ближайший шаг - сбор тестовой выборки и evaluation модели для сравнения с дальнейшими улучшениями базовой модели. Направление дальнейшего исследования - DL для NLP в задаче ранжирования, с учетом особенностей нашей задачи. В частности, нужно учитывать то, что в нашей задаче объектами для ранжирования служат товары, а не чистые тексты, а также то, что мы пока будем решать эту задачу как unsupervised, то есть у нас отстутствует разметка, которая обычно есть в задачах ранжирования.


**1.11.2020** Поучаствовал в хакатоне Лидеры Цифровой Трансформации https://hack2020.innoagency.ru/ по треку Разработка умного правового помощника для предпринимателей.

**2.11.2020** Занял 1 место в вышеупомянутом хакатоне. Приз - 1 млн рублей. Задача была: Разработка умного правового помощника для предпринимателей.<br>
**30.11.2020** Занял 2 место в соревновании по Data Science от архипелага 20.35 https://online.innoagency.ru/datascience/. Приз - 100к рублей. Задача: Разработка алгоритма на основе искусственного интеллекта для автоматизированной оценки комплектности и качества неструктурированного (в т.ч. визуального) содержимого документов, подаваемых в составе заявки на меры государственной поддержки

**14.02.2021** Готовлюсь к пересдаче по БММО до 18-го февраля, поэтому пока не могу активно заняться дипломной работой (активно включусь сразу же как сдам)

**21.02.2021** Начинаю активно заниматься дипломом. Нашел соревнование: https://boosters.pro/championship/data_fusion/overview во второй задаче которого нужно находить бренд товара в текстовой строчке. Как мне кажется, это отличная подзадача для задачи построения поисковой системы в интернет магазине. Поэтому я буду решать это соревнование, искать и изучать современные подходы к решению такого рода задач, и на основе полученных знаний и проведенных экспериментов создавать основу для поиска. Составлю некоторый план работы (над дипломом в целом) с дедлайнами для самого себя, чтобы не потеряться во времени. Опубликую его сюда же.

**22.02.2021** Обговорили с Алексеем дальнейшее сотрудничество. Как оказалось на практике, чат-ботом для ТЦ пользуется довольно мало людей (порядка десятка в день), поэтому провести качественные A/B тестирования различных гипотез будет проблематично. Поэтому решили так: я независимо веду разработку поиска, а потом мы его внедряем в чат-бота (без AB тестов). Ориентировочная дата, к которой должен быть готов пилотный проект - конец марта 2021 года. 

**01.02.2021** Посмотрел лекцию из CS224n по LM и RNN, разобрался в алгоритме Backpropagation through time (backprop для RNN).

**06.02.2021** Изучил GRU и LSTM тут http://d2l.ai/chapter_recurrent-modern/lstm.html (очень хороший онлайн-учебник по дип лернингу)

**07.02.2021** Приступил к соревнованию, пока тестирую NER на основе трансформера.

**08.02.2021** Разметка в соревновании просто ужасная. ![image](https://user-images.githubusercontent.com/20703486/110515749-c7222000-8119-11eb-899b-c604c5668c4f.png) <- тут очевидно бренд campina fruttis, а в лейбле стоит просто fruttis. И так примеров куча...

**09.02.2021** Весь день сидел на tokenizer'ом от HuggingFace, пытался понять что он делает и почему жрет 60 гигов ОЗУ.... В итоге вроде как придется токенизировать по батчам, иначе с трудом влезает в мои 64 гига озу (а на соревновании решение запускается у них на сервере в докере, в котором дается 46 Гб)

**10.02.2021** Наконец-то завел на NER RuBERT через HuggingFace. Правда, учится это все очень долго... 1 эпоха на моей видеокарте будет идти порядка 4 часов. Буду думать, где бы обучить по-быстрее....![image](https://user-images.githubusercontent.com/20703486/110581347-65929d80-817b-11eb-82da-714b24130ec1.png)

**11.02.2021** Обучил за 8 часов 2 эпохи. В качестве претрейненной модели взял RuBERT от Deep Pavlov (через HuggingFace).

Проблема номер 1: как оказалось, в соревновании в качестве решения можно отправлять архивы размером <= 500 мегабайт. Однако мой обученный берт занимает порядка 700 мегабайт. Если сжимать веса в zip архив, выйдет порядка 650 мегабайт... Казалось бы, проблему можноо решить просто взял берта меньше (small версию), но оказывается, что таких бертов, обученных на русский текст, банально нет (либо я пока недостаточно хорошо гуглил). Мои идеи, что делать: либо предобучать свой маленький берт (скорей всего у меня на это не будет ресурсов, потому что берт предобучается на космическом количестве данных), либо гуглить лучше, чтобы найти RuBERT с меньшим числом параметром, либо брать мультиязычные версии берта (не уверен, что они также бывают маленькие), либо отходиь от берта и пытаться решать задачу другими архитектурами.

Проблема номер 2. Пока что не получилось нормально сделать инференс на обученной модельке. Возможнно, это потому что сейчас 5 утра. Попробую продолжить завтра.

Первая проблема меня прямо сильно напрягает, потому что я планировал брать берта в качестве бейзлайна и мне прямо совсем не хочется уходить на другую модель. В худшем случае придется забить на соревнование и работать сразу над моделью для диплома. В частности, надо будет придумать, как сгенерировать данные (либо как их размечать).

Также, в принципе у меня выстроилась основная идея диплома - это построение NER для поисковых запросах. То есть человек задает запрос, я прогоняю его через NER, выделяю ключевые фичи, строю признаковое описание, а дальше выполняю уже линейный поиск по базе товаров в магазинах, которые я спаршу с сайтов. Соответственно в дипломе будет описана модель, фичи, а также тонкости, свзанные с конкретной задачей (как улучшить общую задачу NER под конкретно этот случай). Мне кажется, получится неплохо, однако время уже поджимает...

**14.02.2021** Удалось завести инференс. Пример предикта залью в директорию в competition/outputs. На вид качество плохое, но на самом деле в разметке точно так же, точность на рандомной выборке из общего датасета (трейн + тест, тк я забыл сохранить индексы трейна/теста) порядка 95%, здесь я под точностью понимаю посимвольное совпадение брендов, выделенных сеткой, и того текста, который написан в лебле.

Для решения задачи с 500 мегабайтами мне более опытные товарищи предложили обрезать модель до fp16 (грубо говоря выкинуть точность весов). Так модель сжимается до 350 мегабайт и можно уже попробовать впихнуть все это дело в сабмит. Попробую это сделать на днях. Если все-таки получится засабмитить, то я попробую несколько идей для улучшения модели (связанные они с другим способом простановки тегов словам), а также поучу больше эпох (если мне получится починить куду на сервере с 2х 2080ti видеокартами).

**16.02.2021** Сабмит отказывается работать на boosters, при этом в логах (которые выдает 1 человек в телеграме раз в день) пусто. Явно не лучшее соревнование, если добавить к этому действительно отвратительную разметку.

**17.03.2021** Связался с организаторами, попросил помощи с сабмитом, поскольку я физически не знаю, почему он не заходит. Обещали помочь, но в итоге пропали и 0 ответов и 0 приветов. Скорей всего на соревнование я забью (я им прям совсем недоволен), минимальные навыки для работы с бертом для NER я получил, сейчас я займусь поиском следующих вещей:
1) датасетом с поискомыми запросами (если он будет неразмеченный, посмотрю, во сколько мне обойдется разметка на сервисах для краудсорсинга)
2) статей, связанных с моей задачей. В принципе, как мне кажется, здесь можно придумать различные нетривиальные подходы к извлечению именованных сущностей, которые бы выходили за рамки берта. К примеру, очевидно, что часто бренд представляет собой слово не из словаря (если, само собой, берт не обучался на данные, связанные с брендами). Поэтому, как мне кажется, тут можно прикрутить базу известных слов для сопоставления с тем, что получила нейросеть, чтобы повысить итоговое качество

**23.03.2021** Пока беда с датасетами, решил пособирать сам с озона/яндекс маркета, но там стоит защита от скрапинга... Буду думать

UPD: нашел замечательный сайт https://xmldatafeed.com/ , где все уже сделали за меня. Вопрос только в количестве данных - а хватит ли? Но, скорей всего, если сузить область поиска на, к примеру, технику и около того, то будет вполне. Так что можно считать, что у меня есть датасет сырых названий товаров с некскольких интернет-магазинов (или их аггрегаторов типа озона, яндекс маркета и goods.ru). С его помощью я планирую выполнить некоторый pretrain. К примеру, я могу выучить составить словарь и выучить эмбеддинги для слов.

Но я на самом деле впал в некоторый ступор, что делать дальше. Я изначально хотел сделать так: я беру датасет "живых" запросов людей, размечаю его на token classification (к примеру, это слово в запросе - бренд, это - название товара, а это - уточняющая информация), далее я обучаю NER модель на это, а далее, при поступлении очередного запроса, я прогоняю его через модель, вытаскивать по словам, составляю некоторый вектор, который описается запрос (в сущности это будет категориальный вектор, состоящий из бренда, товара, категории и тд), и ищу по базе наиболее похожее, и выдаю как результат. У этого подхода есть 2 большие проблемы:

1) Негде взять датасет "живых" запросов людей, а сгенерированные датасеты это всегда очень плохо
2) Нет базы, в которой каждый товар бы четко описывался признаками (это надо долго скрапить всякие озоны, которые делают все, чтобы их не скрапили). А даже если бы она была, разные категории товаров описываются сильно разными фичами. К примеру, для телевизоров важен размер (диагональ), для одежды размер, для продуктов состав, для кастрюли объем и тд). И непонятно, как все такие фичи объединять. Как вариант - сделать огромное количество полей в базе, и будет так, что у товара почти все поля пустые (тк при таком подходе у кастрюли будут поля "тактовая частота", "количество страниц" и тд, которые ей достались от других категорий товаров). В принципе, имея очень большие датасеты запросов и большую базу, наверное, это бы могло работать. Но в моем случае у меня нет ни датасетов, ни мощностей, ни времени для такого. 

То есть пока что мое затруднение в плане проектирования проекта: я не знаю, в каком формате должны описываться товары. Исходная задача: текстовый запрос от пользователи -> ему выдаются товары, наиболее релевантные его запросу. Скажем, у товара есть айди, и, зная айди товара, можно получить его полное неформальное описание, которое видит юзер. Но вопрос в том, какое описание товаров имеет алгоритм? В простейшем виде это одна текстовая строчка, к примеру "Чайник Bosch TWK7604, клюквенно-красный". Можно повышать детализацию и разбивать описание товара в базе по признакам: {'Brand':'Bosch', 'Цвет':'Клюквенно-красный', 'Название товара':'Чайник ....', 'Категория':'Чайники', 'Производственный код':'TWK7604'}. Но, как я уже написал выше, с такой детализацией проблемы: 1) сложне собирать данные 2) сложнее унифицировать данные, у разные категорий будут разные поля.

Соответственно мои ближайшие задачи
1) Продолжаю искать релевантные датасеты
2) Обдумываю, какой подход использовать. Скорей всего будет что-то смешанное: товар будет описываться одной текстовой строчкой, но при этом запрос юзера будет распознаваться по сущностям, а дальше будет производиться поиск по всем описаниям товаров, у которых встретился бренд/категория/уточняющая информация. Это также поможет контролировать "важность" признаков, при условии, что точного совпадения нет. К примеру, если был запрос "штаны adidas", а штанов адидас в базе нет, то что лучше выдать пользователю: штаны другого бренда или другой товар от фирмы адидас? Возможно, описания товаров будут также храниться в промежуточном виде между точной детализацией по признакам и единой строчкой. К примеру, все описания будут классифицрованы по категориям и брендам (к примеру: техника, bosch). Это ускорит поиск и повысит качество

**26.03.2021** Никаких публичных датасетов я не нашел. Нашел https://www.kaggle.com/dataturks/best-buy-ecommerce-ner-dataset , который бы идеально мне подошел, но в архиве с датасетом нет ничего, кроме картинки, а на других сайтах его тоже нет.

Однако, даже из безвыходной ситуации было найдено решение. Подход к сбору текстовых запросов такой: будем считать, что довольно часто человек задает свой запрос не напрямую в интернет-магазине (к примеру, в озоне), а вбивает его в поисковик типа гугла. А дальше уже с поисковика он переходит на сайт интернет магазина. Отсюда можно сделать предположение, что большинство переходов с поисковиков на интернет-магазины происходят как раз по запросу поиска некоторого товара. И если бы я мог такие запросы получить, то я бы смог получить нужный мне датасет. К счастью, существуют сайты, которое такое позволяют сделать. К примеру, https://keys.so или https://ahrefs.com/ . Они в основном используются веб и сео мастерами для анализа сайтов конкурентов, трафика и т.д. Но с их помощью мне удалось пока получить некоторый набор запросов, ведущих на озон. Пример из этого дасета:
![image](https://user-images.githubusercontent.com/20703486/112698744-69246500-8e9b-11eb-8daa-c72816b19c58.png)

В принципе, датасет не идеальный и есть шумы, но ничего лучше пока придумать не удалось.

**28.03.2021** Прочитал статью (лежит в papers/done/named_entity.pdf), которая достаточно сильно релевантна к моей работе. Там люди создавали поисковую систему для большого интернет-магазина. По большому счету они сделали то, что намечал я, но они сделали все на основе BiLSTM. Я же планирую в качестве основной модели для распознавания именованных сущностей брать BERT, так что моя работа не будет копией их статьи (к тому же, можно будет сравнить результаты).

Помимо этого, со мной связался тим лид из компании KazanExpress (как я понял, это казанский аналог озона), который предложил на безвозмедной основе предоставить датасет поисковых запросов юзеров. Если у меня с ним все сложится, будет очень хорошо.

Также, я довольно долго обдумывал постановку задачи (то, какая именно будет архитектура). Пока что я решил, что сделаю сравнение 2 вариантов. В обоих случаях база товаров магазина будет представлять собой просто текстовые строчки, в которые написано все описание товара.
1) Запрос юзера перегоняется в эмбеддинг (к примеру, с помощью Sentence BERT), вся база товаров магазина также превращается в эмбеддининги. А дальше выполняется similarity search (просто через расстояние евклида или косинусную меру). Юзеру выдается top-k наиболее похожих вариантов. Здесь же можно перекинуть мостик к моей курсовой работе (быстрый поиск ближайших соседей), и упомянуть способы, как быстро приближенно искать ближайших соседей в пространствах высокой размерности.
2) Метод на основе распознавания именованных сущностей. Похожий метод как раз был в указанной выше статье. Определяются 2 класса сущностей: бренд и название товара. Дальшее из запроса пользователя вытаскиваются эти именованные сущности (с помощью нейросетки). Предполагается, что в базе товаров указано название товара и бренд. Соответственно по этим двум аттрибутам ведется более точный поиск. К примеру, человек задал запрос "купить чайник Bosch объем 2 литра" => происходит классификация токенов: "Bosch" - бренд, "чайник" - название товара. Далее открывается база чайников, в ней база Bosch, и по текстовым строчкам в ней ведется поиск текст "2 литра" (надо кстати подумать, что сделать со словом "купить", возможно банально удалять в препроцессинге). Собственно для реализации такого подхода будет нужна разметка + разметка товаров по названиям товаров и брендов. 

**5.04.2021** Получил данные от компании KazanExpress, сделал слайды для доклада по Switch Transformer.
