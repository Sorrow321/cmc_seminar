\begin{frame}
	\titlepage
\end{frame}

\begin{frame}{Постановка задачи}
	Требуется построить систему, которая бы по поисковому запросу пользователя выдавала релевантные товары в интернет магазине.\\
	
	В данной работе рассматривается подход с использованием технологий NLP и глубокого обучения.
\end{frame}

\begin{frame}{Постановка задачи}
    Будем считать, что для товаров в базе магазина отдельно выделен бренд и название товара.\\
	\begin{figure}[H]
		\includegraphics[width=0.7\textwidth]{p1.jpg}
		\label{fig:sample}
	\end{figure}
    
    Тогда поставленную задачу можно решать с помощью распознавания именованных сущностей (NER) в запросах пользователей.
	\begin{figure}[H]
		\includegraphics[width=0.7\textwidth]{p2.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}

\begin{frame}{Особенности сбора данных}
    Названия/описания товаров можно собирать с интернет-магазинов (на практике это нетривиальная задача)\\

	В открытых источниках отсутствуют наборы данных с запросами пользователей, поскольку область сильно коммерциализована.\\
	
	Большое спасибо компании KazanExpress за предоставленный датасет запросов!   
\end{frame}

\begin{frame}{Особенности сбора данных}
    Предложен метод сбора данных-запросов, если нет возможности обратиться к какой-либо компании за данными.
    
    Анализ трафика переходов на сайты интернет-магазинов с поисковиков (Google, Яндекс и т.д.). Существуют сервисы, которые подобные данные предоставляются (ahrefs.com).

	\begin{figure}[H]
		\includegraphics[width=0.7\textwidth]{ahrefs.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}

\begin{frame}{Всего собранных данных}
\begin{itemize}
    \item 450.000 товаров, собранных с интернет-магазинов Ozon/Юлмарт/BERU/Яндекс.Маркет
    \item 3.1 млн. товаров, описанных в чеке - с соревнования DataFusion
    \item 3.7 млн. неразмеченных запросов - предоставлены KazanExpress
    \item 10.000 размеченных запросов - немного, т.к. разметка за свой счет
\end{itemize}
\end{frame}

\begin{frame}{Модель}
    BERT для распознавания именованных сущностей. В наиболее похожей по смыслу статье от компании TheHomeDepot использовались рекуррентные модели BiLSTM-CRF и BiGRU. В этом основное отличие моей работы и их статьи.\\\\
    BERT предобучался на всем корпусе текстов на задачу предсказания замаскированных слов, а потом дообучался на задачу NER на небольшом (10.000 сэмплов) размеченном датасете запросов.\\
    

\end{frame}

\begin{frame}{Токенизатор}
    В качестве токенизатора - свой обученный WordPiece. Обучен на всем корпусе текстов (на 30 тыс. токенов). Разбиение на подслова способствует повышению качества модели (т.к. пользователи допускают опечатки в запросах, и, если ошибка произошла, то ошибется только в одном субтокене).
    
	\begin{figure}[H]
		\includegraphics[width=0.5\textwidth]{tok.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}

\begin{frame}{Лосс на обучении/валидации}
	\begin{figure}[H]
		\includegraphics[width=0.45\textwidth]{loss_pretrain.jpg}
		\label{fig:sample}
	\end{figure}

	\begin{figure}[H]
		\includegraphics[width=0.45\textwidth]{loss_ner.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}

\begin{frame}{Пример работы (предсказание маскированных слов)}
	\begin{figure}[H]
		\includegraphics[width=0.45\textwidth]{mlm.jpg}
		\label{fig:sample}
	\end{figure}
	

\end{frame}
\begin{frame}{Пример работы (предсказание маскированных слов)}
	Как бонус - можно использовать для автоматического предложения новых слов запросе
	\begin{figure}[H]
		\includegraphics[width=0.45\textwidth]{mlm2.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}
\begin{frame}{Пример работы (распознавание именованных сущностей)}
	\begin{figure}[H]
		\includegraphics[width=0.45\textwidth]{ner.jpg}
		\label{fig:sample}
	\end{figure}
\end{frame}

\begin{frame}{Приложение}
Весь код и обученные модели доступны на GitHub автора: https://github.com/Sorrow321/cmc\_seminar\\

Можно самостоятельно проверить эксперименты и результаты. Данные для обучения не выкладываются, поскольку была просьба от KazanExpress их не разглашать.
\end{frame}

\begin{frame}{Заключение}
\begin{itemize}
    \item Были указаны ключевые сложности со сбором данных
    \item Был предложен метод сбора запросов пользователей в интернет-магазины через посредников --- общие поисковые системы (Яндекс, Google и т.д.)
    \item Был собран обучающий набор данных, часть из них была вручную размечена
    \item Была предложена нейросетевая архитектура, основанная на BERT, для решения поставленной задачи
    \item Был предложен метод токенизации входных запросов, который способствует более качественной работе модели в случае, когда пользователь допустил опечатку в запросе
    \item Были построены прототипы моделей, решающих поставленные задачи
    \item Был предложен метод предсказания следующего слова в запросе
\end{itemize}
\end{frame}